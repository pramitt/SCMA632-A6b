{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b840e5c0-c77b-4bee-b6f6-017fba59dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen, VECM\n",
    "from statsmodels.tsa.api import VAR\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "930f7ce9-8820-4446-bc28-56a7143e7a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:\\\\Users\\\\prami\\\\Desktop\\\\SCMA 632\\\\SCMA 632\\\\assignments\\\\A6b\\\\pinksheet.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name=\"Monthly Prices\", skiprows=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc386872-f34d-459f-aa54-9325238b3c31",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"1960M0101\" doesn't match format \"%Y%m%d\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Newfolder3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1112\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1111\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1112\u001b[0m         values \u001b[38;5;241m=\u001b[39m convert_listlike(arg\u001b[38;5;241m.\u001b[39m_values, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1113\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mD:\\Newfolder3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:488\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[0;32m    490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    491\u001b[0m     arg,\n\u001b[0;32m    492\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    496\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m )\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Newfolder3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:519\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    509\u001b[0m     arg,\n\u001b[0;32m    510\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    514\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    515\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    516\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 519\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m array_strptime(arg, fmt, exact\u001b[38;5;241m=\u001b[39mexact, errors\u001b[38;5;241m=\u001b[39merrors, utc\u001b[38;5;241m=\u001b[39mutc)\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[1;32mstrptime.pyx:534\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:355\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"1960M0101\" doesn't match format \"%Y%m%d\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "df.rename(columns={df.columns[0]: 'Date'}, inplace=True)\n",
    "df['Date'] = pd.to_datetime(df['Date'].astype(str) + '01', format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e6e1d1f-3c17-4eb4-95e5-37ea32b6b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={df.columns[0]: 'Date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c32ce853-78c8-43f2-ba8a-25e617e78480",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'].astype(str) + '-01', format='%YM%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da04be22-a300-4097-96fb-446e583f45de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date           datetime64[ns]\n",
      "CRUDE_PETRO           float64\n",
      "CRUDE_BRENT           float64\n",
      "CRUDE_DUBAI           float64\n",
      "CRUDE_WTI              object\n",
      "                    ...      \n",
      "NICKEL                float64\n",
      "Zinc                  float64\n",
      "GOLD                  float64\n",
      "PLATINUM              float64\n",
      "SILVER                float64\n",
      "Length: 72, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0449dcb-3d86-4fc5-b4ab-2c754b88cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity = df.iloc[:, [0, 2, 24, 69, 71, 60, 30]].copy()\n",
    "commodity.columns = commodity.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fffc776-e24b-4922-90b8-cf12cdcd12c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_data = commodity.drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8c58ca8-1a98-433a-8165-26551f95b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_test = commodity_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f53110b7-295a-4f16-abd7-438040357c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_stationary_count = 0\n",
    "stationary_columns = []\n",
    "non_stationary_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "076226b2-46af-48ce-bf4b-29ab8b7b1de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ADF test result for column: crude_brent\n",
      "ADF Statistic: -1.5078661910935343, p-value: 0.5296165197702398\n",
      "\n",
      "ADF test result for column: soybeans\n",
      "ADF Statistic: -2.42314645274189, p-value: 0.13530977427790403\n",
      "\n",
      "ADF test result for column: gold\n",
      "ADF Statistic: 1.3430517021933006, p-value: 0.9968394353612382\n",
      "\n",
      "ADF test result for column: silver\n",
      "ADF Statistic: -1.397294710746222, p-value: 0.5835723787985764\n",
      "\n",
      "ADF test result for column: urea_ee_bulk\n",
      "ADF Statistic: -2.5101716315209086, p-value: 0.11301903181624645\n",
      "\n",
      "ADF test result for column: maize\n",
      "ADF Statistic: -2.4700451060920425, p-value: 0.12293380919376751\n"
     ]
    }
   ],
   "source": [
    "for col in columns_to_test:\n",
    "    adf_result = adfuller(commodity_data[col], regression='c', autolag='AIC')\n",
    "    p_value = adf_result[1]\n",
    "    print(f\"\\nADF test result for column: {col}\")\n",
    "    print(f\"ADF Statistic: {adf_result[0]}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d64c20b-881e-4b87-a996-b432988df0bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1888837493.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "if p_value > 0.05:\n",
    "  non_stationary_count += 1\n",
    "  non_stationary_columns.append(col)\n",
    "    else:\n",
    "        stationary_columns.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3045aa4-8648-494e-8869-00956cf45d1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:4\u001b[1;36m\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "if p_value > 0.05:\n",
    "        non_stationary_count += 1\n",
    "        non_stationary_columns.append(col)\n",
    "    else:\n",
    "        stationary_columns.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c79a130e-487d-4b4f-8b19-74b01389d998",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2443925374.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    if p_value > 0.05:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " # Check if the p-value is greater than 0.05 (commonly used threshold)\n",
    "    if p_value > 0.05:\n",
    "        non_stationary_count += 1\n",
    "        non_stationary_columns.append(col)\n",
    "    else:\n",
    "        stationary_columns.append(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "297a6fa0-dd50-4355-9e1e-240522a58e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of non-stationary columns: 0\n",
      "Non-stationary columns: []\n",
      "Stationary columns: []\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nNumber of non-stationary columns: {non_stationary_count}\")\n",
    "print(f\"Non-stationary columns: {non_stationary_columns}\")\n",
    "print(f\"Stationary columns: {stationary_columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3aa1fc0-4adf-45fb-b1b8-db173816280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-Integration Test (Johansen's Test)\n",
    "# Determining the number of lags to use (you can use information criteria like AIC, BIC)\n",
    "model = VAR(commodity_data)\n",
    "lags = model.select_order(maxlags=10)\n",
    "lag_length = lags.selected_orders['aic']  # Choosing the lag with the lowest AIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1826b2b-4bd2-4474-82a2-8fcc5c3071ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
